\documentclass[journal,twoside]{JoPhA}
\usepackage[utf8]{inputenc}
\usepackage{flushend}
\usepackage{graphicx}


\begin{document}

\title{Predicción de mortalidad en accidentes de tráfico}
 
\author{Samuel Rey y David Moreno
\IEEEcompsocitemizethanks{\IEEEcompsocthanksitem Samuel Rey y David Moreno - Universidad Rey Juan Carlos\protect\\

E-mail: samuel.rey.escudero@gmail.com, dmorenolumb@gmail.com.es
%\IEEEcompsocthanksitem Vicente Matell\'an is with University of Rey Juan Carlos.
} % <-this % s
}


\maketitle


\begin{abstract}
% Yo
	
Resumen
\end{abstract}


\section{Introduction}
\IEEEPARstart{L}a predicción de los accidentes de tráfico es uno de los mayores retos de la actual sociedad debido al alto coste económico y, sobre todo, humano que conllevan. Las técnicas de análisis de datos y aprendizaje máquina (\textit{Machine Learning}) ofrecen una oportunidad única para analizar y comprender las razones subyacentes que provocan estos accidentes, otorgando la oportunidad de, en última instancia, predecirlos. En este contexto, los datos recopilados de accidentes anteriores permiten analizar en detalle los factores involucrados para buscar tendencias o patrones. Sin embargo, existen diversos factores que hacen que el análisis de los datos y su utilización para futuras predicciones sea un verdadero reto: \\

\begin{itemize}
	\item Las bases de datos son muy grandes y heterogéneas, por lo que habitualmente no se puede trabajar con datos de distintas procedencias. \\
	
	\item Los datos son introducidos manualmente por personas, por lo que son propensos a errores o valores inádecuado y a presentar ruido. Sobre este tema se profundiza algo más en el artículo \cite{analisis_datos}. \\

	\item Las situaciones reales son complejas y sus datos cuentan con un gran número de atributos, por lo que los modelos utilizados para predecir los resultados tienen una gran dimensionalidad y requieren un gran número de ejemplos. \\
\end{itemize}

% Quitar??
%La utilidad y a la vez, dificultad que esta situación presenta, así como la actual relevancia que está adquiriendo el campo de análisis de datos y aprendizaje máquina, ha motivado la realización de un datatón y concurso en la universidad Rey Juan Carlos. En este datatón se proporcionarán conocimientos básicos en estas materias así como distintos consejos para abordar el problema, haciendo un ranking de las distintas soluciones obtenidas y premiando las dos primeras. \\

En este artículo, para abordar este problema nos centraremos en predecir la gravedad del accidente, abordándolo como un problema de clasificación binaria. Basándonos en los atributos número de heridos leves, número de heridos graves y número de muertos, las clases que hemos definido son: \\

\begin{itemize}
	\item \textit{Clase 0 - Accidente leve}: consideraremos accidetentes leves todos aquellos en los que no haya ni muertos ni heridos.
	\item \textit{Clase 1 - Accidente grave}: clasificaremos como accidentes graves aquellos en los que haya habido muertos o heridos, ya sean leves o graves.
\end{itemize}

Esta definición de clases ha sido establecida por el concurso organizado en el datatón de la universidad Rey Juan Carlos, y la máquina explicada en este artículo ha sido ha sido propuesta como solución. Esto supone una dificultad añadida, dado que el conjunto de test utilizado para evaluar las diferentes máquinas presentadas al concurso tenía las clases desbalanceadas. Aproximadamente el 75\% de elementos del conjunto de tests pertenecían a la clase 1, mientras que sólo el 25\% representaban a la clase 0. Sin embargo, el conjunto de datos de entrenamiento no estaba desbalanceado. En él, el 54\% de las observaciones pertenecían a la clase 1 y el 46\% restante a la clase 0. \\

La base de datos utilizada consta de más de 9000 observaciones, con 83 atributos cada una. Se trata de datos muy ruidosos y de una gran dimensionalidad, algo que resulta especialmente problemático, como se explica en \cite{alta_dimensionalidad}. Además, la mayoría de los atributos son paramétricos, por lo que presenta pocos outliers. Sin embargo, algunos atributos tenían un gran númro de elementos incorrectos. Todo esto hace que sea necesario una primera fase de procesamiento de datos y selección de características antes de elegir y entrenar el modelo, para utilizar tener en cuenta sólo las características que realmente aportan información y ayudan a mejorar el rendimiento de la máquina. Esta fase de análisis de datos es especialmente importante, dado que evita ayuda a evitar sobreaujustes y que el modelo aprenda errores existentes en los datos o incluso el ruido. Cómo se comenta en \cite{extraccion_datos}, un buen análisis previo puede conseguir que un modelo sencillo supere el rendimiento de modelos mucho más complejos. \\

A continuación, se explicara detalladamente la metodología empleada para resolver el problema. Se explicará en que ha consistido el análisis de datos realizado, los distintos modelos que se han considerado para resolver el problema y las figuras de mérito que hemos considerado. Después, detallaremos los dos modelos que han dado un mejor resultado comentando los parámetros de cada uno, y para finalizar, expondremos las conclusiones a las que hemos llegado después de enfrentarnos a este problema. \\

\section{Metodología}
\subsection{Análisis de datos}
\IEEEPARstart{A}l tratarse de datos con una dimensionalidad tan alta y tanto ruido, es imprescindible realizar un buen análisis de los datos y una fase de extracción de características. Para esto, lo primero que hemos hecho ha sido revisar los datos con los que hemos trabajado. De esta forma hemos detectado los atributos que no aportaban información, como el \textit{Número de accidente} o el \textit{id}, y los hemos eliminado. Así mismo, hemos detectado atributos en los que más del 90\% de las observaciones tenían un valor de \textit{NaN}. Este análisis también nos ha permitido detectar información recibida. Por ejemplo, los campos \textit{Carretera}, \textit{Km} y \textit{Pk} están ya recogidos en las coordenadas GPS. \\

A continuación, hemos representado cada atributo restante mediante gráficos de barras, para visualizar el número de accidentes de cada clase para los distintos valores de los atributos. Con esto, buscábamos encontrar las características que no aparentemente no aportasen ningún tipo de información para eleminarlas del conjunto de datos, reduciendo así la dimensionalidad. Además del análisis visual, antes de decidir si borrar o no una característica, hemos comparado los resultados obtenidos entrenando la máquina con y sin ella, eliminándola unicamente si no mejoraba el resultado. \\

% TODO: alguna imagen de las gráficas y referenciarla

Tras este prceso de análisis y extracción de características, hemos conseguido reducir el número de atributos de [INDICA CUANTO!!] a [INDICA CUANTO!!]. \\

Cómo la dimensionnalidad de los datos seguía siendo muy elevada, hemos utilizado los siguientes métodos de extracción de características para seleccionar las K mejores: \\

\begin{itemize}
	\item Principal Component Analysis
	\item Truncated Singular Value Decomposition
	\item Información mutua
	\item Mayor varianza
\end{itemize}

Para cada método hemos probado diferentes valores de K, pero en todos los casos el resultado empeoraba al aplicar la extracción de caraterísticas. \\

\subsection{Selección del modelo}
Después de la extración de características, el principal problema al que nos hemos enfrentado ha sido elegir el modelo más adecuado para este problema de clasificación. Los modelos considerados han sido los sigientes: \\

\begin{itemize}
	\item MLP
	\item SVM
	\item K-vecinos
	\item PNN
	\item Regresor logístico
\end{itemize} 

Tras ajustar estos modelos, los que han ofrecido un mejor resutado han sido el SVM y el MLP, por lo que nos hemos centrado especialmente en ajustar lo mejor posible los parámetros de estos dos modelos. \\

El 80\% de los datos disponibles se han utilizado para el conjunto de entrenamiento y el 20\% restante para el conjunto de validación, utilizado para medir las prestaciones del modelo. La separación de estos grupos se ha realizado de forma aleatoria. \\

La figura de mérito que empleamos inicialmente para valorar los modelos fue la \textit{accuracy}. Los evaluamos utilizando valiadción cruzada, dividiendo los datos e grupos de 10. Sin embargo, al darnos cuenta que el conjunto de test estaba desbalanceado cambiamos la forma de evaluar los modelos. Utilizando los datos de la matriz de confusión, utilizamos cómo métrica la \textit{precision} y el \textit{recall}, de cada clase por separado y de media. Al haber más elementos de la clase 1 que de la case 0, nos centramos especialmente en conseguir un modelo con buenos resultados para dicha clase. De esta forma, al seleccionar el modelo, considerábamos un coste muy elevado a clasificar un elemento de la clase 1 como un elemento de la clase 0, mientras el caso contrario tenía un coste mucho más reducido. \\



\section{Resultados}
\IEEEPARstart{I}ntroducción
	\subsection{SVM}
	% David

	\subsection{MLP}
	% Yo


\section{Conclusiones}
% David

\section*{Acknowledgment??}
This  research  has  been  partially  sponsored  by  the Community of Madrid through the RoboCity2030-III project (S2013/MIT-2748), by the Spanish Ministerio de Economía y Competitividad through the SIRMAVED project (DPI2013-40534-R) and by the URJC-BancoSantander.
%CVIP.

\begin{thebibliography}{1}

\bibitem{analisis_datos}
Figuera, C., Lillo, J. M., Mora-Jimenez, I., Rojo-Álvarez, J. L., \& Caamaño, A. J. (2011, October). \emph{Multivariate spatial clustering of traffic accidents for local profiling of risk factors.} In Intelligent Transportation Systems (ITSC), 2011 14th International IEEE Conference on (pp. 740-745). IEEE.

\bibitem{extraccion_datos}
Mitchell, T. M. (2006). \emph{The discipline of machine learning (Vol. 9).} Carnegie Mellon University, School of Computer Science, Machine Learning Department.

\bibitem{alta_dimensionalidad}
Domingos, P. (2012). \emph{A few useful things to know about machine learning.} Communications of the ACM, 55(10), 78-87.

\end{thebibliography}
\end{document}


